# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.
# Users should configure the fine_tune_checkpoint field in the train config as
# well as the label_map_path and input_path fields in the train_input_reader and
# eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
# should be configured.

model {
  faster_rcnn {
    num_classes: 120                         #class 개수
    image_resizer {                           #GPU에는 많은 메모리를 요구하기 때문에 이미지들을 최적(최소, 최대)의 크기로 축소함
      keep_aspect_ratio_resizer {
        min_dimension: 600                 #최소 규모
        max_dimension: 1024               #최대 규모
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_v2'
      first_stage_features_stride: 16      #이미지에서 사물을 찾을 수 있는 위치와 이동 방법인 stride는 16이여야함 굳이 변경해야 된다면 8과 4로 변경
    }
    first_stage_anchor_generator {
      grid_anchor_generator {     #여기에 많은 작은 이미지가 생성됨. 즉 이미지에서 class의 매트릭스를 찾을 수 있음. 이미지를 찾을 수 있는 앵커 포인트들을 만듬
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {   #컨볼루션 매개변수
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01   #과도하게 조여지면 안되므로 0.01로 설정 네트워크를 수정할 수 있는 좋은 척도
        }
      }
    }
    first_stage_nms_score_threshold: 0.0              #0으로 설정해야 모든 값이 유지됨 ex) 0.1로 설정하면 10%정보가 날라감
    first_stage_nms_iou_threshold: 0.7                 #iou 0.7로 설정해야 bounding box를 잘 찾음
    first_stage_max_proposals: 300                     #훈련을 멋진 값으로 세트를 잘라냄 기준 300으로 100으로 설정할수도있음
    first_stage_localization_loss_weight: 2.0           #위치 loss
    first_stage_objectness_loss_weight: 1.0           #객체 loss
    initial_crop_size: 14                                   #이건 왜 이 크기로 크롭하는지 코드를 봐도 정보를 찾을 수 없음... 만든 사람만 알듯..
    maxpool_kernel_size: 2                              #레이어에 이미지를 얼마나 축소할 지 하는 maxpooling 다들 아실거라 생각해서 넘어감
    maxpool_stride: 2                                     #2의 보폭은 이미지를 반으로 잘라냄 ㅎㅎ
    second_stage_box_predictor {         #이게 네트워크
      mask_rcnn_box_predictor {           #레이어가 완전히 연결되어 있고 설정할 수 있도록 모든 것을 유지하려는 경우 
        use_dropout: false                   #이 시점에서 drop out한 레이어는 사용하지 않음 그래서 false로 설정 
        dropout_keep_probability: 1.0      #1로 설정해야댐 
        fc_hyperparams {  
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0                #0으로 설정 L2의 가중치 값을 조정하면 모델을 가질 확률이 저하됨 
            }
          }
          initializer {                       #L2 조정하기 위해 이게 있음
            variance_scaling_initializer {
              factor: 1.0                    
              uniform: true               #Input image와 output image 사이에 균일해야하고 평균으로 조정하기 위해 true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {   #output 정보
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6                       #iou 교차점 0.6으로 설정
        max_detections_per_class: 100        #한 이미지의 각각의 class 100개이상을 찾으면 100개까지만 찾음 
        max_total_detections: 300             #class 개수를 찾을 수 있는 개수 300개
      }
      score_converter: SOFTMAX             #object detection은 무조건 softmax사용!  클래스 감지를 위해서는 softmax가 조오춍~!
    }
    second_stage_localization_loss_weight: 2.0         #이 단계에서 loss도 당연히 중요 어떻게 설정하는지는 
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {            #batch size, learning rate 등등 캡슐화함
  batch_size: 1                  #batch size는 1로만 설정함 
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0002         초기학습에 이거고
          schedule {
            step: 900000                  #step 900000에선 learning rate를 줄임
            learning_rate: .00002
          }
          schedule {
            step: 1200000
            learning_rate: .000002        #이것또한 마찬가지
          }
        }
      }
      momentum_optimizer_value: 0.9       #줄여야 결과를 더 빨리 찾을 수 있음 다만, 보다 올바른 결과를 찾기 위핸 높여야됨 0.9가 적당
    }
    use_moving_average: false               #캐시된 값이 푸시 속도를 늦추므로 가중치를 얼마나 변경하고 싶은지 하는 피쳐
  }
  gradient_clipping_by_norm: 10.0         #오버플로가 되지 않도록 하는 방법 이떄 10을 넘기면 안된다고 함. 
  fine_tune_checkpoint: "C:/models-master/research/object_detection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt"
  from_detection_checkpoint: true
  load_all_detection_checkpoint_vars: true
  # Note: The below line limits the training process to 200K steps, which we
  # empirically found to be sufficient enough to train the pets dataset. This
  # effectively bypasses the learning rate schedule (the learning rate will
  # never decay). Remove the below line to train indefinitely.
  num_steps: 800000                        #이게 훈련 step임 우리가 무조건 건드려야 할것 
  data_augmentation_options {            #데이터 augmentation 옵션임 수평 뒤집기를 사용함
    random_horizontal_flip {
    }
  }
}


train_input_reader: {
  tf_record_input_reader { #tfrecord로된 훈련 데이터 경로
    input_path: "C:/Users/young/FileDetection/dog_breed_test/dog_detection/archive/fine_tuning_practice/tfrecord_file/train_labels.record"
  }#labelmap 경로
  label_map_path: "C:/models-master/research/object_detection/training/label_map.pbtxt"
}

eval_config: {
  metrics_set: "coco_detection_metrics"
  num_examples: 4032             #validatation할 이미지 개수
}

eval_input_reader: {
  tf_record_input_reader { #validatation할 tfrecord 경로
    input_path: "C:/Users/young/FileDetection/dog_breed_test/dog_detection/archive/fine_tuning_practice/tfrecord_file/test_labels.record"
  }#labelmap 경로
  label_map_path: "C:/models-master/research/object_detection/training/label_map.pbtxt"
  shuffle: false
  num_readers: 1
}
